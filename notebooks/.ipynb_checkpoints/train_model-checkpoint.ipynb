{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09613a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import ConfusionMatrix, ROC\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ROC, ConfusionMatrix, AUROC, AveragePrecision\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a225775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "from PIL import Image\n",
    "\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.corrupted_images = []  # Store names of corrupted images\n",
    "       \n",
    "        # Collect all image paths\n",
    "        for label, subdir in enumerate([\"Real\", \"Fake\"]):\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            if os.path.exists(subdir_path):\n",
    "                for img_name in os.listdir(subdir_path):\n",
    "                    img_path = os.path.join(subdir_path, img_name)\n",
    "                    if img_name.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "        # Validate images but do not remove them\n",
    "        for path in self.image_paths:\n",
    "            try:\n",
    "                with Image.open(path) as img:\n",
    "                    img.verify()  # Check if the image is valid\n",
    "            except (OSError, IOError):\n",
    "                self.corrupted_images.append(path)  # Store corrupted image name\n",
    "\n",
    "        # Print corrupted image names if found\n",
    "        if self.corrupted_images:\n",
    "            print(\"\\nCorrupted Images Detected:\")\n",
    "            for img_path in self.corrupted_images:\n",
    "                print(img_path)\n",
    "        else:\n",
    "            print(\"\\nNo corrupted images found.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except (OSError, IOError):\n",
    "            print(f\"Warning: Unable to open {image_path}. Returning blank image.\")\n",
    "            image = Image.new(\"RGB\", (512, 512), (0, 0, 0))  # Return a black image\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = DeepfakeDataset(root_dir=\"/home/libra-03/Desktop/DL_Assignment/new_sample_1.8L/Train\", transform=transform)\n",
    "val_dataset = DeepfakeDataset(root_dir=\"/home/libra-03/Desktop/DL_Assignment/new_sample_1.8L/Val\", transform=transform)\n",
    "test_dataset = DeepfakeDataset(root_dir=\"/home/libra-03/Desktop/DL_Assignment/new_sample_1.8L/Test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f28ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class DeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepfakeDetector, self).__init__()\n",
    "        self.model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(self.model.classifier[1].in_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "   \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d220d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using GPU\")\n",
    "model = DeepfakeDetector().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "       \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "       \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "       \n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_model(model, train_loader, val_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "    \n",
    "    # Generate Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Real\", \"Fake\"], yticklabels=[\"Real\", \"Fake\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    # False Positive Rate (FPR) & False Negative Rate (FNR)\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tn = cm[0][0]\n",
    "    tp = cm[1][1]\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr:.2f}\")\n",
    "\n",
    "# Call the function\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "torch.save(model.state_dict(), \"DESIRED PATH TO MODEL.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Model will be saved in:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66d958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
