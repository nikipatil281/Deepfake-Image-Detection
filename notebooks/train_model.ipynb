{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09613a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import ConfusionMatrix, ROC\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ROC, ConfusionMatrix, AUROC, AveragePrecision\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a225775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "from PIL import Image\n",
    "\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.corrupted_images = []  # Store names of corrupted images\n",
    "       \n",
    "        # Collect all image paths\n",
    "        for label, subdir in enumerate([\"Real\", \"Fake\"]):\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            if os.path.exists(subdir_path):\n",
    "                for img_name in os.listdir(subdir_path):\n",
    "                    img_path = os.path.join(subdir_path, img_name)\n",
    "                    if img_name.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "        # Validate images but do not remove them\n",
    "        for path in self.image_paths:\n",
    "            try:\n",
    "                with Image.open(path) as img:\n",
    "                    img.verify()  # Check if the image is valid\n",
    "            except (OSError, IOError):\n",
    "                self.corrupted_images.append(path)  # Store corrupted image name\n",
    "\n",
    "        # Print corrupted image names if found\n",
    "        if self.corrupted_images:\n",
    "            print(\"\\nCorrupted Images Detected:\")\n",
    "            for img_path in self.corrupted_images:\n",
    "                print(img_path)\n",
    "        else:\n",
    "            print(\"\\nNo corrupted images found.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except (OSError, IOError):\n",
    "            print(f\"Warning: Unable to open {image_path}. Returning blank image.\")\n",
    "            image = Image.new(\"RGB\", (512, 512), (0, 0, 0))  # Return a black image\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6a1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No corrupted images found.\n",
      "\n",
      "No corrupted images found.\n",
      "\n",
      "No corrupted images found.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = DeepfakeDataset(root_dir=\"/home/libra-03/Desktop/DL_Assignment/new_sample_1.8L/Train\", transform=transform)\n",
    "val_dataset = DeepfakeDataset(root_dir=\"/home/libra-03/Desktop/DL_Assignment/new_sample_1.8L/Val\", transform=transform)\n",
    "test_dataset = DeepfakeDataset(root_dir=\"/home/libra-03/Desktop/DL_Assignment/new_sample_1.8L/Test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f28ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class DeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepfakeDetector, self).__init__()\n",
    "        self.model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(self.model.classifier[1].in_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "   \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d220d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# Training Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using GPU\")\n",
    "model = DeepfakeDetector().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b35f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "       \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "       \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "       \n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2022\n",
      "Validation Loss: 0.1286, Accuracy: 95.34%\n",
      "Epoch 2, Loss: 0.1401\n",
      "Validation Loss: 0.1115, Accuracy: 95.79%\n",
      "Epoch 3, Loss: 0.1228\n",
      "Validation Loss: 0.0955, Accuracy: 96.41%\n",
      "Epoch 4, Loss: 0.1127\n",
      "Validation Loss: 0.0897, Accuracy: 96.58%\n",
      "Epoch 5, Loss: 0.1049\n",
      "Validation Loss: 0.0872, Accuracy: 96.62%\n",
      "Epoch 6, Loss: 0.0992\n",
      "Validation Loss: 0.0802, Accuracy: 96.83%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_model(model, train_loader, val_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b812f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "    \n",
    "    # Generate Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Real\", \"Fake\"], yticklabels=[\"Real\", \"Fake\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    # False Positive Rate (FPR) & False Negative Rate (FNR)\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tn = cm[0][0]\n",
    "    tp = cm[1][1]\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr:.2f}\")\n",
    "\n",
    "# Call the function\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfc11122",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchmetrics.classification import ConfusionMatrix, ROC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(\"cuda\"), labels.to(\"cuda\").unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            y_true.extend(labels.cpu().numpy().flatten())\n",
    "            y_pred.extend(predicted.cpu().numpy().flatten())\n",
    "            y_scores.extend(probs.cpu().numpy().flatten())\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    y_true_tensor = torch.tensor(y_true, dtype=torch.int)\n",
    "    y_pred_tensor = torch.tensor(y_pred, dtype=torch.int)\n",
    "    y_scores_tensor = torch.tensor(y_scores, dtype=torch.float32)\n",
    "\n",
    "    # Compute and plot confusion matrix\n",
    "    cm = ConfusionMatrix(num_classes=2, task=\"binary\")(y_pred_tensor, y_true_tensor).numpy()\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Real\", \"Fake\"], yticklabels=[\"Real\", \"Fake\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute and plot ROC curve\n",
    "    fpr, tpr, _ = ROC(task=\"binary\")(y_scores_tensor, y_true_tensor)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute classification metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_scores)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc_roc\n",
    "\n",
    "# Call the function\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "torch.save(model.state_dict(), \"Sample_new_1.8L_20_epochs_deepfake_detector_linkedin.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Model will be saved in:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28fd9cfd",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "def rename_files(folder_path):\n",
    "    files = sorted(os.listdir(folder_path))  # Sort to maintain order\n",
    "    for index, file in enumerate(files, start=1):\n",
    "        old_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(old_path):  # Ensure it's a file\n",
    "            new_name = f\"this_mac_image_{index}{os.path.splitext(file)[1]}\"  # Preserve original extension\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f'Renamed: {file} -> {new_name}')\n",
    "\n",
    "folder_path = input(\"Enter the folder path: \")\n",
    "rename_files(folder_path)\n",
    "\n",
    "\n",
    "print(\"rename completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66d958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
